from typing import List, Dict, Optional
from pubmed_search import PubMedSearcher
from medical_analyzer import MedicalAnalyzer
from paper_summarizer import PaperSummarizer
import time

class MedicalSearchService:
    def __init__(self):
        self.pubmed_searcher = PubMedSearcher()
        self.medical_analyzer = MedicalAnalyzer()
        self.paper_summarizer = PaperSummarizer()
    
    def search_medical_papers(self, user_input: str, max_results: int = 10) -> Dict:
        """ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ìš”ì•½"""
        
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        
        # 1. ì˜ë£Œ ê°œì²´ ë¶„ì„
        entities = self.medical_analyzer.analyze_input(user_input)
        
        # 2. ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        search_query = self.medical_analyzer.generate_search_query(entities, user_input)
        
        # 3. ìˆ˜ì¹˜ í•´ì„
        interpretations = self.medical_analyzer.interpret_values(entities)
        
        # 4. PubMed ê²€ìƒ‰ (ë” ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ í•„í„°ë§)
        papers = self.pubmed_searcher.search_and_fetch(search_query, max_results * 2)
        
        # 5. ë…¼ë¬¸ ìš”ì•½ ë° ê´€ë ¨ì„± í‰ê°€
        summarized_papers = []
        if papers:
            summarized_papers = self.paper_summarizer.summarize_papers(papers, user_input)
            
            # 6. ë…¼ë¬¸ í•„í„°ë§ ë° ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (ìµœì í™”)
            filtered_papers = []
            min_relevance_threshold = 0.10  # ê¸°ë³¸ 10%
            
            # Spinal Cord Stimulation íŠ¹ë³„ ì²˜ë¦¬
            is_scs_search = any(term in user_input.lower() for term in ['spinal cord stimulation', 'scs', 'ì²™ìˆ˜ìê·¹ìˆ '])
            
            if is_scs_search:
                print(f"ğŸ¯ SCS ì „ìš© í•„í„°ë§ ì ìš©")
                # SCS ê²€ìƒ‰ì˜ ê²½ìš° ë§¤ìš° ê´€ëŒ€í•œ í•„í„°ë§
                for paper in papers:
                    title = paper.get('title', '').lower()
                    abstract = paper.get('abstract', '').lower()
                    content = title + ' ' + abstract
                    
                    # SCS ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (íŠ¹ë³„ ë¡œì§)
                    scs_score = 0
                    
                    # ì§ì ‘ì ì¸ SCS ì–¸ê¸‰
                    if 'spinal cord stimulation' in content:
                        scs_score += 0.7
                    elif 'scs' in content and ('pain' in content or 'stimulation' in content):
                        scs_score += 0.5
                    elif 'neurostimulation' in content and 'spinal' in content:
                        scs_score += 0.4
                    
                    # ê´€ë ¨ ì˜ë£Œ ìš©ì–´
                    if any(term in content for term in ['chronic pain', 'neuropathic pain', 'back pain']):
                        scs_score += 0.2
                    if any(term in content for term in ['implantable', 'device', 'electrode']):
                        scs_score += 0.1
                    if any(term in content for term in ['efficacy', 'effectiveness', 'outcome']):
                        scs_score += 0.1
                    
                    # ëª…ë°±íˆ ê´€ë ¨ ì—†ëŠ” ë‚´ìš© ì œì™¸
                    exclude_terms = ['veterinary', 'animal model only', 'plant', 'agriculture', 'in vitro only']
                    has_exclude = any(term in content for term in exclude_terms)
                    
                    if scs_score >= 0.05 and not has_exclude:  # ë§¤ìš° ë‚®ì€ ì„ê³„ê°’
                        paper['relevance_score'] = scs_score
                        filtered_papers.append(paper)
            else:
                # ì¼ë°˜ì ì¸ í•„í„°ë§ ë¡œì§
                for paper in papers:
                    title = paper.get('title', '').lower()
                    abstract = paper.get('abstract', '').lower()
                    content = title + ' ' + abstract
                    
                    # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                    relevance_score = self._calculate_relevance_score(paper, entities, user_input)
                    paper['relevance_score'] = relevance_score
                    
                    # ê¸°ë³¸ ì œì™¸ íŒ¨í„´ (ë§¤ìš° ì œí•œì )
                    exclude_patterns = [
                        'veterinary medicine', 'animal study only', 'plant biology', 
                        'agricultural research', 'environmental policy only'
                    ]
                    
                    has_exclude_pattern = any(pattern in content for pattern in exclude_patterns)
                    is_low_relevance = relevance_score < min_relevance_threshold
                    
                    # íŠ¹ë³„ ì¼€ì´ìŠ¤: ê³ ì§€í˜ˆì¦ ê´€ë ¨ ê²€ìƒ‰ì˜ ê²½ìš° ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©
                    is_hyperlipidemia_search = any(term in user_input.lower() for term in ['ê³ ì§€í˜ˆ', 'ì½œë ˆìŠ¤í…Œë¡¤', 'cholesterol', 'lipid', 'hyperlipidemia'])
                    if is_hyperlipidemia_search:
                        hyperlipidemia_keywords = ['hyperlipidemia', 'dyslipidemia', 'cholesterol', 'lipid', 'triglyceride', 'statin', 'atherosclerosis']
                        has_hyperlipidemia_content = any(keyword in content for keyword in hyperlipidemia_keywords)
                        if has_hyperlipidemia_content:
                            is_low_relevance = relevance_score < 0.08
                    
                    # ìµœì¢… í•„í„°ë§ ì¡°ê±´
                    should_include = not is_low_relevance and not has_exclude_pattern
                    
                    if should_include:
                        filtered_papers.append(paper)
            
            # ê´€ë ¨ì„± ì ìˆ˜ë¡œ ì¬ì •ë ¬í•˜ê³  ìš”ì²­ëœ ìˆ˜ë§Œí¼ë§Œ ë°˜í™˜
            filtered_papers.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
            summarized_papers = filtered_papers[:max_results]
        
        # 7. ì „ì²´ ìš”ì•½ ìƒì„±
        overall_summary = self.paper_summarizer.generate_overall_summary(summarized_papers, user_input)
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = round(time.time() - start_time, 2)
        
        return {
            'user_input': user_input,
            'search_query': search_query,
            'detected_entities': [
                {
                    'text': entity.text,
                    'type': entity.entity_type,
                    'value': entity.value,
                    'unit': entity.unit,
                    'normal_range': entity.normal_range
                } for entity in entities
            ],
            'interpretations': interpretations,
            'papers': summarized_papers,
            'total_papers_found': len(papers),  # ì›ë³¸ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            'filtered_papers_count': len(summarized_papers),  # í•„í„°ë§ í›„ ìˆ˜
            'overall_summary': overall_summary,
            'processing_time': processing_time,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
    
    def get_paper_detail(self, pmid: str) -> Optional[Dict]:
        """íŠ¹ì • ë…¼ë¬¸ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        papers = self.pubmed_searcher.fetch_paper_details([pmid])
        if papers:
            return papers[0]
        return None
    
    def search_similar_papers(self, pmid: str, max_results: int = 5) -> List[Dict]:
        """íŠ¹ì • ë…¼ë¬¸ê³¼ ìœ ì‚¬í•œ ë…¼ë¬¸ ê²€ìƒ‰"""
        # ì›ë³¸ ë…¼ë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        original_paper = self.get_paper_detail(pmid)
        if not original_paper:
            return []
        
        # ì œëª©ê³¼ ì´ˆë¡ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ê²€ìƒ‰
        title = original_paper.get('title', '')
        abstract = original_paper.get('abstract', '')
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš© ê°€ëŠ¥)
        keywords = self._extract_keywords_from_text(title + ' ' + abstract)
        search_query = ' AND '.join([f'"{kw}"' for kw in keywords[:3]])
        
        # ê²€ìƒ‰ ë° ì›ë³¸ ë…¼ë¬¸ ì œì™¸
        papers = self.pubmed_searcher.search_and_fetch(search_query, max_results + 1)
        similar_papers = [p for p in papers if p.get('pmid') != pmid][:max_results]
        
        return similar_papers
    
    def _extract_keywords_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)"""
        import re
        
        # ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬
        text = text.lower()
        words = re.findall(r'\b[a-zA-Z]{4,}\b', text)  # 4ê¸€ì ì´ìƒ ì˜ì–´ ë‹¨ì–´
        
        # ì˜í•™ ìš©ì–´ë¡œ ë³´ì´ëŠ” ë‹¨ì–´ë“¤ ìš°ì„ ì„ ë³„
        medical_keywords = []
        common_words = {'with', 'from', 'they', 'this', 'that', 'were', 'been', 'have', 'more', 'such', 'also', 'than', 'only', 'these', 'may', 'can', 'between', 'after', 'before', 'during', 'study', 'studies', 'analysis', 'results', 'methods', 'patients', 'data', 'using', 'used', 'show', 'showed', 'found', 'observed'}
        
        for word in words:
            if word not in common_words and len(word) >= 4:
                medical_keywords.append(word)
                if len(medical_keywords) >= 5:  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ
                    break
        
        return medical_keywords
    
    def _calculate_relevance_score(self, paper: Dict, entities: List, user_input: str) -> float:
        """ë…¼ë¬¸ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        title = paper.get('title', '').lower()
        abstract = paper.get('abstract', '').lower()
        content = title + ' ' + abstract
        user_lower = user_input.lower()
        
        # 1. ì‚¬ìš©ì ì…ë ¥ê³¼ì˜ ì§ì ‘ì ì¸ ë§¤ì¹­
        user_words = user_lower.split()
        for word in user_words:
            if len(word) > 2:  # 2ê¸€ì ì´ìƒì˜ ë‹¨ì–´ë§Œ
                if word in title:
                    score += 0.05  # ì œëª©ì— ìˆìœ¼ë©´ 5%
                elif word in abstract:
                    score += 0.02  # ì´ˆë¡ì— ìˆìœ¼ë©´ 2%
        
        # 2. ê°ì§€ëœ ì—”í‹°í‹°ì™€ì˜ ë§¤ì¹­
        for entity in entities:
            entity_text = entity.text.lower()
            if entity_text in content:
                if entity.entity_type == 'disease':
                    score += 0.04  # ì§ˆë³‘ëª… ë§¤ì¹­
                elif entity.entity_type == 'test':
                    score += 0.03  # ê²€ì‚¬ëª… ë§¤ì¹­
                elif entity.entity_type == 'treatment':
                    score += 0.04  # ì¹˜ë£Œë²• ë§¤ì¹­
        
        # 3. í•œêµ­ì–´ ì˜ë£Œ ìš©ì–´ ì¸ì‹
        korean_medical_terms = {
            'ë‹¹ë‡¨ë³‘': 'diabetes', 'ê³ í˜ˆì••': 'hypertension', 'íŒŒí‚¨ìŠ¨': 'parkinson',
            'ì•”': 'cancer', 'ì¢…ì–‘': 'tumor', 'ì‹¬ì¥': 'heart', 'ë‡Œ': 'brain',
            'ì¹˜ë£Œ': 'treatment', 'ì§„ë‹¨': 'diagnosis', 'ìˆ˜ìˆ ': 'surgery',
            'íš¨ëŠ¥': 'efficacy', 'íš¨ê³¼': 'effectiveness'
        }
        
        for korean, english in korean_medical_terms.items():
            if korean in user_lower and english in content:
                score += 0.03
        
        # 4. ê¸°ë³¸ ì˜ë£Œ í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤
        medical_keywords = [
            'patient', 'clinical', 'treatment', 'therapy', 'diagnosis', 'disease',
            'medical', 'health', 'study', 'trial', 'efficacy', 'outcome', 'hospital'
        ]
        
        for keyword in medical_keywords:
            if keyword in content:
                score += 0.01
        
        # 5. CA-125 íŠ¹ë³„ ì²˜ë¦¬
        if any(term in user_lower for term in ['ca 125', 'ca-125', 'ca125']):
            if any(term in content for term in ['ca-125', 'ca 125', 'tumor marker', 'ovarian cancer']):
                score += 0.1  # ë†’ì€ ë³´ë„ˆìŠ¤
        
        return min(score, 1.0)  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
    
    def get_health_tips(self, entities: List) -> List[str]:
        """ê°ì§€ëœ ì˜ë£Œ ê°œì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±´ê°• íŒ ì œê³µ"""
        tips = []
        
        for entity_data in entities:
            entity_type = entity_data.get('type')
            entity_text = entity_data.get('text', '').lower()
            
            if entity_type == 'test':
                if 'crp' in entity_text:
                    tips.append("ğŸ’¡ CRP ìˆ˜ì¹˜ê°€ ë†’ë‹¤ë©´ ì—¼ì¦ì„ ì¤„ì´ê¸° ìœ„í•´ ê¸ˆì—°, ê·œì¹™ì ì¸ ìš´ë™, ê±´ê°•í•œ ì‹ë‹¨ì„ ìœ ì§€í•˜ì„¸ìš”.")
                elif 'hba1c' in entity_text or 'glucose' in entity_text:
                    tips.append("ğŸ’¡ í˜ˆë‹¹ ê´€ë¦¬ë¥¼ ìœ„í•´ íƒ„ìˆ˜í™”ë¬¼ ì„­ì·¨ë¥¼ ì¡°ì ˆí•˜ê³  ì •ê¸°ì ì¸ ìš´ë™ì„ í•˜ì„¸ìš”.")
                elif 'cholesterol' in entity_text:
                    tips.append("ğŸ’¡ ì½œë ˆìŠ¤í…Œë¡¤ ê´€ë¦¬ë¥¼ ìœ„í•´ í¬í™”ì§€ë°© ì„­ì·¨ë¥¼ ì¤„ì´ê³  ì˜¤ë©”ê°€-3ê°€ í’ë¶€í•œ ìŒì‹ì„ ì„­ì·¨í•˜ì„¸ìš”.")
                elif 'bp' in entity_text:
                    tips.append("ğŸ’¡ í˜ˆì•• ê´€ë¦¬ë¥¼ ìœ„í•´ ë‚˜íŠ¸ë¥¨ ì„­ì·¨ë¥¼ ì¤„ì´ê³  ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ê´€ë¦¬í•˜ì„¸ìš”.")
            
            elif entity_type == 'disease':
                if 'ë‹¹ë‡¨ë³‘' in entity_text or 'diabetes' in entity_text:
                    tips.append("ğŸ’¡ ë‹¹ë‡¨ë³‘ ê´€ë¦¬: ì •ê¸°ì ì¸ í˜ˆë‹¹ ì¸¡ì •, ê· í˜•ì¡íŒ ì‹ë‹¨, ê·œì¹™ì ì¸ ìš´ë™ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.")
                elif 'ê³ í˜ˆì••' in entity_text or 'hypertension' in entity_text:
                    tips.append("ğŸ’¡ ê³ í˜ˆì•• ê´€ë¦¬: ì—¼ë¶„ ì„­ì·¨ ì œí•œ, ì •ê¸°ì ì¸ í˜ˆì•• ì¸¡ì •, ê¸ˆì—°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì¼ë°˜ì ì¸ ê±´ê°• íŒ
        if not tips:
            tips.append("ğŸ’¡ ì •ê¸°ì ì¸ ê±´ê°•ê²€ì§„ê³¼ ì˜ì‚¬ì™€ì˜ ìƒë‹´ì„ í†µí•´ ê±´ê°•ì„ ê´€ë¦¬í•˜ì„¸ìš”.")
        
        return tips
    
    def format_search_results(self, results: Dict) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        output = []
        
        # í—¤ë”
        output.append("ğŸ” PubMed ì˜ë£Œ ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼")
        output.append("=" * 50)
        output.append(f"ê²€ìƒ‰ì–´: {results['user_input']}")
        output.append(f"ê²€ìƒ‰ ì‹œê°„: {results['timestamp']}")
        output.append(f"ì²˜ë¦¬ ì‹œê°„: {results['processing_time']}ì´ˆ")
        output.append("")
        
        # ê°ì§€ëœ ì˜ë£Œ ê°œì²´
        if results['detected_entities']:
            output.append("ğŸ“Š ê°ì§€ëœ ì˜ë£Œ ì •ë³´:")
            for entity in results['detected_entities']:
                if entity['value']:
                    output.append(f"  â€¢ {entity['text']} ({entity['type']})")
                else:
                    output.append(f"  â€¢ {entity['text']} ({entity['type']})")
            output.append("")
        
        # ìˆ˜ì¹˜ í•´ì„
        if results['interpretations']:
            output.append("ğŸ“ˆ ìˆ˜ì¹˜ í•´ì„:")
            for interpretation in results['interpretations']:
                output.append(f"  â€¢ {interpretation}")
            output.append("")
        
        # ì „ì²´ ìš”ì•½
        if results['overall_summary']:
            output.append("ğŸ“‹ ì¢…í•© ìš”ì•½:")
            output.append(f"  {results['overall_summary']}")
            output.append("")
        
        # ë…¼ë¬¸ ëª©ë¡
        output.append(f"ğŸ“š ê´€ë ¨ ë…¼ë¬¸ ({results['total_papers_found']}ê°œ ë°œê²¬):")
        output.append("")
        
        for i, paper in enumerate(results['papers'][:5], 1):  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            output.append(f"{i}. {paper['title']}")
            
            if paper['authors']:
                authors = ', '.join(paper['authors'][:3])  # ì²˜ìŒ 3ëª…ë§Œ
                if len(paper['authors']) > 3:
                    authors += " ì™¸"
                output.append(f"   ì €ì: {authors}")
            
            if paper['journal']:
                output.append(f"   ì €ë„: {paper['journal']}")
            
            if paper['publication_date']:
                output.append(f"   ë°œí–‰ì¼: {paper['publication_date']}")
            
            output.append(f"   PMID: {paper['pmid']}")
            output.append(f"   ë§í¬: {paper['pubmed_url']}")
            
            if paper['ai_summary']:
                output.append(f"   ìš”ì•½: {paper['ai_summary'][:200]}...")
            
            output.append("")
        
        return "\n".join(output) 